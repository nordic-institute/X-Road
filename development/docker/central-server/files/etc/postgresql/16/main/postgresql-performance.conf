# PostgreSQL Performance Configuration for Single-Session Optimization
# This configuration is optimized for single-session performance with 4 CPU cores
# Memory settings assume at least 2GB RAM available for PostgreSQL
# Adjust based on your actual available memory

#------------------------------------------------------------------------------
# MEMORY SETTINGS
#------------------------------------------------------------------------------
# MEMORY USAGE BREAKDOWN:
# - BASELINE (always allocated at startup): shared_buffers + wal_buffers = ~544MB
# - ON-DEMAND (only when needed): work_mem, maintenance_work_mem
# - PLANNER HINT (not allocated): effective_cache_size
#
# Current baseline: ~544MB (512MB shared_buffers + 32MB wal_buffers)
# Optimized for slow storage (GitHub Actions) - higher caching reduces I/O
# To reduce baseline: lower shared_buffers to 256MB, wal_buffers to 16MB
# For fast local SSD: can reduce shared_buffers to 256MB-512MB

# Shared memory buffers (ALWAYS ALLOCATED - baseline memory usage)
# Higher values = better cache hit ratio, less I/O (critical for slow storage)
# Default: 128MB
# For slow I/O (GitHub Actions): 512MB-1GB recommended
# For fast I/O (local SSD): 256MB-512MB sufficient
shared_buffers = 512MB  # Increased for slow storage environments

# Effective cache size (PLANNER HINT ONLY - not actual memory allocation)
# This tells PostgreSQL how much memory is available for caching (OS cache + shared_buffers)
# Used by query planner to choose better plans, doesn't allocate memory
# Default: 4GB, Recommended: 50-75% of total RAM available to PostgreSQL
effective_cache_size = 1536MB

# Work memory per operation (ONLY USED WHEN NEEDED - not baseline)
# This is used for sorting, hash joins, etc. per operation
# With single session, this can be much higher since only one connection uses it
# Higher values = better performance for complex queries, but only allocated during operations
# Default: 4MB, Recommended for single session: 64MB-256MB
work_mem = 128MB

# Maintenance work memory (for VACUUM, CREATE INDEX, etc.)
# Increased for faster index creation in Liquibase schema operations
# Default: 64MB, Recommended: 256MB-512MB
maintenance_work_mem = 512MB

# WAL buffers (ALWAYS ALLOCATED - baseline memory usage)
# Higher values = more buffering, less frequent I/O (better for slow storage)
# Default: -1 (auto, ~16MB), Recommended: 16MB-32MB
# For slow storage: 32MB-64MB to reduce I/O frequency
wal_buffers = 32MB  # Increased for slow storage environments

#------------------------------------------------------------------------------
# QUERY TUNING
#------------------------------------------------------------------------------

# Random page cost (optimized for storage type)
# For SSD: 1.1-1.5, For slow storage (GitHub Actions): 2.0-3.0
# Lower value = planner prefers random I/O (good for SSD)
# Higher value = planner prefers sequential I/O (better for slow storage)
# Using 1.5 as compromise - can be tuned based on environment
random_page_cost = 1.5

# Effective IO concurrency (optimized for storage type)
# For SSD: 200-300, For slow storage: 50-100
# Lower for slow storage to reduce I/O queue depth
# Using 100 as compromise - can be tuned based on environment
effective_io_concurrency = 100

# Default statistics target (higher = better query plans, more time to analyze)
# Default: 100, Recommended: 200-500
default_statistics_target = 200

#------------------------------------------------------------------------------
# PARALLEL QUERY SETTINGS
#------------------------------------------------------------------------------

# Maximum worker processes (should match CPU cores)
# Default: 8, Recommended for 4 cores: 4
max_worker_processes = 4

# Maximum parallel workers per gather
# Default: 2, Recommended for 4 cores: 2-3
max_parallel_workers_per_gather = 2

# Maximum parallel workers
# Default: 8, Recommended for 4 cores: 4
max_parallel_workers = 4

# Minimum parallel table scan size
# Default: 8MB, Recommended: 1MB-2MB (allows more parallel scans)
min_parallel_table_scan_size = 1MB

# Minimum parallel index scan size
# Default: 512kB, Recommended: 512kB (keep default)
min_parallel_index_scan_size = 512kB

#------------------------------------------------------------------------------
# WRITE PERFORMANCE
#------------------------------------------------------------------------------

# Checkpoint completion target (0.0-1.0)
# Higher values spread checkpoint I/O over more time
# Default: 0.9, Recommended: 0.9-0.95
checkpoint_completion_target = 0.9

# Maximum WAL size before checkpoint
# Default: 1GB, Recommended: 2GB-4GB
max_wal_size = 2GB

# Minimum WAL size before checkpoint
# Default: 80MB, Recommended: 256MB-512MB
min_wal_size = 256MB

#------------------------------------------------------------------------------
# CONNECTION SETTINGS
#------------------------------------------------------------------------------

# Maximum connections (lower is fine for single session focus)
# Default: 100, Recommended for single session: 20-50
max_connections = 100

#------------------------------------------------------------------------------
# LOGGING (optional, can help with debugging slow queries)
#------------------------------------------------------------------------------

# Log slow queries (uncomment if needed)
# log_min_duration_statement = 1000  # Log queries taking longer than 1 second

#------------------------------------------------------------------------------
# AUTOVACUUM & STATISTICS (optimized for frequent schema drops/recreates)
#------------------------------------------------------------------------------

# Autovacuum is important for performance
autovacuum = on

# More aggressive autovacuum for frequent schema operations (TEST ENVIRONMENT)
# Lower naptime = more frequent checks, important for frequent drops/recreates
autovacuum_max_workers = 2
autovacuum_naptime = 2s  # Very aggressive for test environments with frequent schema changes

# Auto-analyze settings (critical for query planner performance)
# Force statistics updates more frequently to prevent planner degradation
autovacuum_analyze_scale_factor = 0.01  # Default: 0.1, Lower = analyze more often
autovacuum_analyze_threshold = 10       # Default: 50, Lower = analyze smaller tables

# Autovacuum thresholds (more aggressive for test environments)
autovacuum_vacuum_scale_factor = 0.05   # Default: 0.2, Lower = vacuum more often
autovacuum_vacuum_threshold = 10        # Default: 50, Lower = vacuum smaller tables

# Force statistics collection on schema operations
# This helps prevent query planner degradation over time
default_statistics_target = 100  # Reduced from 200 - faster stats collection, still good plans

#------------------------------------------------------------------------------
# TEST ENVIRONMENT OPTIMIZATIONS (No recovery/audit needed)
#------------------------------------------------------------------------------

# Disable fsync for maximum speed (TEST ONLY - data loss risk on crash)
# This provides significant write performance boost for test environments
# Default: on, For tests: off (much faster writes)
fsync = off

# Disable synchronous commit (TEST ONLY - faster commits, no durability guarantee)
# Default: on, For tests: off
synchronous_commit = off

# Reduce WAL overhead (minimal logging for tests, no recovery needed)
# Default: replica, For tests: minimal (much faster, no point-in-time recovery)
wal_level = minimal

# Disable WAL streaming/replication (TEST ONLY - no replication needed)
# Required when wal_level = minimal, otherwise PostgreSQL will error
# Default: 0, but may be set elsewhere - explicitly disable for tests
max_wal_senders = 0

# Disable replication slots (TEST ONLY - no replication needed)
# Default: 0, but explicitly set for clarity
max_replication_slots = 0

# Disable full page writes (TEST ONLY - faster checkpoints, no crash recovery)
# Default: on, For tests: off
full_page_writes = off

# Reduce checkpoint frequency (less overhead, critical for slow storage)
# Default: 5min, For tests: 15min-30min (less frequent = less I/O)
# For slow storage: longer timeout = fewer checkpoints = better performance
checkpoint_timeout = 30min  # Increased for slow storage environments

# Larger WAL segments before checkpoint (less frequent checkpoints)
# For slow storage: larger = fewer checkpoints = better performance
max_wal_size = 8GB  # Increased from 4GB for slow storage environments

# Disable logging overhead (TEST ONLY - no audit trail needed)
# Default: various logging enabled, For tests: minimal logging
logging_collector = off
log_destination = 'stderr'
log_min_messages = warning
log_min_error_statement = error
log_min_duration_statement = -1  # Disable slow query logging

# Disable statement statistics (reduces overhead)
# Default: on, For tests: off
track_io_timing = off
track_functions = none
track_activity_query_size = 1024  # Smaller than default (2KB)

# Reduce connection overhead
# Default: various, For tests: minimal
log_connections = off
log_disconnections = off
log_duration = off
log_line_prefix = ''  # No prefix overhead

# Reduce query plan statistics overhead (keep track_counts for query planning)
# track_counts should stay on for query optimization, but reduce other stats
# stats_temp_directory = 'pg_stat_tmp'  # Already default

#------------------------------------------------------------------------------
# SLOW STORAGE OPTIMIZATIONS (for GitHub Actions / cloud storage)
#------------------------------------------------------------------------------

# Sequential page cost (for slow storage, prefer sequential I/O)
# Default: 1.0, Lower = prefer sequential scans (better for slow storage)
seq_page_cost = 0.8  # Slightly lower to prefer sequential I/O

# Background writer settings (for slow storage)
# More aggressive background writing to reduce checkpoint I/O spikes
bgwriter_delay = 50ms  # Default: 200ms, Lower = more frequent writes
bgwriter_lru_maxpages = 200  # Default: 100, More pages written per cycle
bgwriter_lru_multiplier = 4.0  # Default: 2.0, More aggressive writing

# Reduce I/O during schema operations
# Batch writes more aggressively
commit_delay = 100000  # Default: 0, Microseconds to delay commit (batch writes)
commit_siblings = 10  # Default: 5, Number of concurrent transactions before batching

#------------------------------------------------------------------------------
# SCHEMA OPERATIONS OPTIMIZATION (for frequent drops/recreates)
#------------------------------------------------------------------------------

# Disable expensive statistics collection that accumulates over time
# These can cause performance degradation with frequent schema operations
track_counts = on  # Keep on - needed for query planning
track_io_timing = off  # Already set above - reduces overhead
track_functions = none  # Already set above - reduces overhead

# Reduce system catalog bloat from frequent schema operations
# Vacuum system catalogs more aggressively
vacuum_cost_delay = 0  # No delay for vacuum operations (TEST ONLY)
vacuum_cost_page_hit = 1  # Default: 1
vacuum_cost_page_miss = 2  # Default: 10, Lower = faster vacuum
vacuum_cost_page_dirty = 5  # Default: 20, Lower = faster vacuum

# Faster DDL operations (for CREATE/DROP TABLE, INDEX, etc.)
# Reduce lock timeouts for schema operations
lock_timeout = 0  # No timeout (TEST ONLY - may cause hangs in production)
statement_timeout = 0  # No timeout (TEST ONLY)

#------------------------------------------------------------------------------
# ANTI-DEGRADATION SETTINGS (prevent performance degradation over time)
#------------------------------------------------------------------------------

# Aggressive autovacuum for system catalogs (pg_class, pg_attribute, etc.)
# System catalogs accumulate metadata even when dropping/recreating schemas
# These settings force more frequent vacuum/analyze of system catalogs
autovacuum_vacuum_insert_threshold = 50  # Default: 1000, Lower = vacuum inserts more often
autovacuum_vacuum_insert_scale_factor = 0.01  # Default: 0.2, Lower = vacuum inserts more aggressively

# Force vacuum on system catalogs more frequently
# System catalogs are small but critical - vacuum them aggressively
# Note: These are global vacuum settings, not autovacuum-specific
vacuum_freeze_min_age = 50000000  # Default: 50M, Lower = freeze tuples sooner
vacuum_multixact_freeze_min_age = 5000000  # Default: 5M, Lower = freeze multixact sooner
# Note: vacuum_freeze_max_age and vacuum_multixact_freeze_max_age are not configurable parameters
# They are controlled by autovacuum_freeze_max_age which is set via ALTER SYSTEM or postgresql.conf
# but may not be available in all PostgreSQL versions - relying on autovacuum defaults

# Disable query plan caching for DDL-heavy workloads
# Prevents caching of plans that become stale quickly
plan_cache_mode = auto  # Default: auto, Can be 'force_custom_plan' to disable caching

# More aggressive vacuum of dead tuples (important for frequent drops/recreates)
# Lower thresholds = vacuum more often, preventing accumulation
autovacuum_vacuum_scale_factor = 0.02  # Default: 0.2, Lower = vacuum smaller tables
autovacuum_vacuum_threshold = 5  # Default: 50, Lower = vacuum very small tables

# Force analyze of system catalogs more frequently
# System catalog statistics degrade over time with frequent schema operations
autovacuum_analyze_scale_factor = 0.005  # Default: 0.1, Even more aggressive (was 0.01)
autovacuum_analyze_threshold = 5  # Default: 50, Even more aggressive (was 10)

# Reduce overhead from statistics queries
# pg_stat_* queries can be slow when tables are large
track_activity_query_size = 512  # Reduced from 1024 - smaller query text storage

